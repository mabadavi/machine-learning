{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0          42           5\n",
      "1          18           2\n",
      "2          42           3\n",
      "3         112           3\n",
      "4          13           1\n",
      "5          12           1\n",
      "6           8           0\n",
      "7          21           2\n",
      "8          83           7\n",
      "9          12           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 131074)\n",
      "(159571, 131074)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 131074)\n",
      "(31915, 131074)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 11)\n",
      "(31915, 11)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='toxiccomments_train.csv', my_random_seed=42)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12981, 'Neg': 114675, 'TP': 11352, 'TN': 113880, 'FP': 795, 'FN': 1629, 'Accuracy': 0.981011468321113, 'Precision': 0.9345517411706594, 'Recall': 0.8745088976195978, 'desc': 'svm_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier(loss='hinge', penalty='elasticnet', alpha=0.001, l1_ratio=0.5, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of false positives:\n",
      "2413\n",
      "Yet another thanks \n",
      "\n",
      "Looks like you keep yourself busy doing this sort of thing, but I'll add my thanks to the list for fixing the stupid vandalism on my User Page.\n",
      "* * * * * * * * * \n",
      "9764\n",
      "Cheers man. To be honest, I laughed my arse out in front of my laptop today. You guys are so funny attacking a beginner and that definitely made my day. Me and my girlfriend just can't stop laughing, seriously, hellish ghoul? ))))). Thanks for your advice I'll consider reading policies tomorrow. Now, the article is not complete, data must be obviously changed and content put in order and completed. However, I'll decide whether to go on or give up this wikipedia thing, since I like reality and palpable history, which is obviously not the case here. Wikipedia is more likely to fit (or create some) American history and culture. Thanks man and forgive my mistakes. They were on purpose. Best of luck to you guys.\n",
      "* * * * * * * * * \n",
      "14598\n",
      "Elonka RFC\n",
      "\n",
      "I'm considering putting Elonka up for RFC seeing as the election process was corrupted.\n",
      "* * * * * * * * * \n",
      "17622\n",
      "And you are wrong about your not being rude. In fact, your persistence proves that you are in fact being rude on purpose.\n",
      "* * * * * * * * * \n",
      "17979\n",
      "I don't care if you put 100 warnings. I'm not a racist, so you take it back. Just because I think there are Hebrew fanatics, and Christian fanatics, and Atheist fanatics it doesn't mean I'm a racist.\n",
      "* * * * * * * * * \n",
      "22715\n",
      "what is a sockpuppet? i've recently made an account as I am sick of carrying an IP address around- you should do the same.\n",
      "* * * * * * * * * \n",
      "22800\n",
      "Cheers\n",
      "Damn fine page.\n",
      "* * * * * * * * * \n",
      "25265\n",
      "is in the discussion page where a suggestion is made. WTF?\n",
      "* * * * * * * * * \n",
      "28860\n",
      "Warning\n",
      "\n",
      "This message is regarding the page Penis. Please refrain from adding nonsense to Wikipedia.  It is considered vandalism.  If you would like to experiment, use the sandbox. —\n",
      "* * * * * * * * * \n",
      "30863\n",
      "Also,Scrapiron Always Talk to shit.You Better Watch Out of his comments.He's a Right Hand Of Zionist.He Controls you out of he that.I Just Want to know that Little Bird is for US Version.MD 500 Defender is for Malaysian army.i out here and im give out.210.186.9.117\n",
      "* * * * * * * * * \n",
      "30865\n",
      "Vandalism Removal \n",
      "\n",
      "Although disagreeing with the validity of such a diet I am sure that the word 'penis' does not belong half way down the section on it's own. As such I have gelded this article and removed it's penis. I couldn't be bothered to sign in to do it but thought I'd better announce it here in case somebody reverted my edit and brought the penis back. 194.223.81.88\n",
      "* * * * * * * * * \n",
      "35476\n",
      "\"\n",
      "\n",
      " Throwing \"\"qualifications\"\" for justification of a certin POV is meaningless.  I can just as easily say that I work in finance, am Scottish, and don a kilt every Thursday to greet wee lasses along the Mile.  Does that make me right? \n",
      "\n",
      "Common sense people.    \"\n",
      "* * * * * * * * * \n",
      "41348\n",
      "\"\n",
      "\n",
      " Another Toronto Cinema \n",
      "\n",
      "Although short-lived (ca 1970 - ca 1978), I think you might wish to include the Cinema Lumiere in your list. It was a small, independent theatre located on College Street about a block west of Spadina. Probably best labeled an \"\"art house\"\", Cinema Lumiere nevertheless showed such cult gems as George Romero's (original) The Night of the Living Dead. Still, more typical were showings of modern European films such as The Night Porter, The Conformist, and so forth.  \"\n",
      "* * * * * * * * * \n",
      "50657\n",
      "\"\n",
      "\n",
      "Your polices are nothing but lies. Also... WTF is an \"\"ip\"\"? Do you mean IP? I suggest you get people to teach your editors basic English.\n",
      "And as a matter of fact, I have an account. And I will edit and spam all I like, good day, cunt. -)\"\n",
      "* * * * * * * * * \n",
      "57114\n",
      "\"\n",
      "\n",
      " Friendly tags \n",
      "\n",
      "Hello, I noticed you've been updating  spout \"\n",
      "* * * * * * * * * \n",
      "60417\n",
      "\"\n",
      "\n",
      "Shut down Wikipedia\n",
      "\n",
      "This is EXACTLY why Wikipedia should be shut down, or at least referenced as a blog instead of an \"\"Encyclopedia\"\" you have a current event that is constantly changing and yet Wikipedia is publishing an article as fact.\"\n",
      "* * * * * * * * * \n",
      "61470\n",
      "\"\n",
      "\n",
      "You are spot on about the propaganda. Thats what this article and mariacahi case is ! so called \"\"pro-life\"\" propaganda.Time to change that. 65.35.249.125  \"\n",
      "* * * * * * * * * \n",
      "64205\n",
      "Regarding laws and homosexuality\n",
      "The following passage has been re-added several times, despite explanations that parts of it violate WP:NPOV and are false, when compared to the source used for the article:\n",
      "\n",
      "Gay and Lesbian tourists should avoid the Cayman Islands because of both the local culture and the fact that certain laws and customs are still in effect from British Colonial rule. Homosexuality is illegal in the Cayman Islands, and gay men and lesbians will be jailed and expelled from the Cayman Islands if caught.\n",
      "\n",
      "The cite, however, makes clear that homosexuality is not illegal in the Caymans, though there is a tradition of homophobia and a documented incident of an American tourist briefly detained for a public show of affection. The cited source makes no mention of likelihood of imprisonment or expulsion. Nor is the exhortation to avoid the Caymans acceptable in an encyclopedia. Further reversions and addition of spurious information may be considered vandalism, and will merit administrators' attention. 99.11.4.201\n",
      "* * * * * * * * * \n",
      "65599\n",
      "Vandalism \n",
      "\n",
      "The other users delete the photo pleas warn other users like me if you are a real counter-vandalist.\n",
      "* * * * * * * * * \n",
      "67934\n",
      "Kalaripatt pic\n",
      "I have tagged several images for the same reason in the past and all of them have been speedy deleted by other admins(as recently as a few hours ago) without harping on me wasting their time or asking me to go through a pointless IFD etc.,..  If you dont want to speedy it, dont.  Another admin will come along and do the honours.  Non-admin editors' time isnt free either and we are all volunteering our valuable time.  So stop acting like its a waste of your time to examine a simple thing like this.  If it really is, you should consider giving up your tools.\n",
      "\n",
      "And whats more, this is an image which I have tagged in the past for precisely the same reason(watermark) and it has been deleted more than once too.  It keeps coming back and you tell me it is a waste of your time that I tag it?  Sarvagnya\n",
      "* * * * * * * * * \n",
      "68365\n",
      "\"\n",
      "Ganging up to exclude a new editor is not \"\"consensus\"\", as any admin will easily see ... so, if you want to get yourselves blocked, pls carry on this pathetic dummy spitting performance ...   \"\n",
      "* * * * * * * * * \n",
      "68711\n",
      "I am a very efficient person, who can steer the ape\n",
      "* * * * * * * * * \n",
      "68872\n",
      "Thanks! ) \n",
      "\n",
      "Hi, just wanted to let you know that I think you're a total loser to be patrolling recent changes.  Go outside and do us all a favor.\n",
      "Note: you ARE being reported for vandalism  stop it.\n",
      "* * * * * * * * * \n",
      "71654\n",
      "Re: spoilers perhaps?\n",
      "i figured after i finished the anime series that there lives would go back to normal. that was 7 months ago. last night i watched the movie and it made me mad it was teh exact opposite of what i was hopeing for. i was hopeing for them to go back home and live with winry the rest of there lives but they stayed on what is portraied as our side of the gate. that really made me mad. but seeing scar and lusts counterparts its kind of ok cause they were two of my favorite  characters. finding out dante was the leader of the homunculi kind of knocked me off balance i figured it wouldent be her i thought it was hoenhime the whole time.\n",
      "* * * * * * * * * \n",
      "72060\n",
      "Would it be easier for you to justify your position if I had disagreed with you in the past? Either way, your behavior is arrogant and your contribution unwanted. Before I answer your question, Samboy, are you, or are you not a complete hypocrite for not signing that post?\n",
      "* * * * * * * * * \n",
      "77092\n",
      "I don't know where you are really from, but it's not just Germany, it is in the US, UK etc, too. They are arresting children and taking them away from their parents! It's gone too far. And it is mostly because of this friggen movement. Don't you see that?  (talk)\n",
      "* * * * * * * * * \n",
      "78071\n",
      "\"\n",
      "And as I told MosMusy, I would strongly consider supporting Armenia for inclusion if there was an outbreak of related Eastern European protests (I don't think a few demonstrations in Albania and Croatia warrant a separate \"\"2011 Eastern European protests\"\" article, certainly, and WP:RS doesn't support the hypothesis that Armenian and Azerbaijani protesters may have drawn inspiration from those countries instead of from Tunisia and Egypt) and Armenia was affected. Ditto Central Asian protests, even. It's a border country, and there are competing definitions. I think as long as we make it very clear in this article that Armenia is politically and culturally linked to Europe (like Turkey) despite the geography, we're doing no disservice.\n",
      "As for the comment deletion, I think one or two users are overwriting the previous version of the page when they encounter an edit conflict rather than copy-and-pasting their comments into the current version. -  \"\n",
      "* * * * * * * * * \n",
      "78771\n",
      "\" For what it's worth, neither the Chinese, Korean or Japanese Wikipedias abbreviate the title using \"\"blah blah\"\" or any of the other alternatives, precisely because they would probably think it would be stupid to have a title which had \"\"blah blah\"\" in it.\"\n",
      "* * * * * * * * * \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80167\n",
      "Don't be a douche, CKATZ.\n",
      "* * * * * * * * * \n",
      "81117\n",
      "Someone Ban Me So My misery posting here is over\n",
      "I am trying hard as hell to be an A$$ to get banned. Make it permanent please. I can then get back to being productive. Well I am waiting. 172.56.11.104\n",
      "* * * * * * * * * \n",
      "90388\n",
      "A JEW?  OR NOT A JEW?\n",
      "* * * * * * * * * \n",
      "91371\n",
      "I am all for a RFC, but moderators should prevent you from flooding the RFC with irrelevancies. I am OK with Encyclopedia's and Dictionaries policies about the usage of foreign languages use. But you have to convince others that a words original version usage should be equivalent to the usage of modern creation.\n",
      "* * * * * * * * * \n",
      "93445\n",
      "Lol, you are too busy doing what now?   Maybe you don't realize it, but no one gives a shit about anything you're doing, because it's a waste of time and no one will ever read it\n",
      "* * * * * * * * * \n",
      "93553\n",
      "Hey Asspro \n",
      "I left a disparaging remark about you on the helpdesk. Enjoy.\n",
      "* * * * * * * * * \n",
      "94777\n",
      "\"  I'm simply leaving out negative things being put onto their wikipedia article that was the result of actions of \"\"azskeptic\"\".  I'm trying to show the positive things about the school and help them with the future while you seem to be on a mission to try to ruin the lives of these people?\"\n",
      "* * * * * * * * * \n",
      "99078\n",
      "Did you poop in your pants? —\n",
      "* * * * * * * * * \n",
      "100404\n",
      "\" (UTC)\n",
      "\n",
      " I agreed with . Frankly speaking,  looks completely right. The general remarks should be written in one article. However, it seems that crazy(, stupid, criminal) admins have already dispersed almost all of decent general editors in the world, who can edit and satisfy .    11:34, 6 March 2015\"\n",
      "* * * * * * * * * \n",
      "103855\n",
      "Banana \n",
      "\n",
      "Hi banana box here's the rear for you!!!!!\n",
      "* * * * * * * * * \n",
      "114627\n",
      "\"\n",
      "\n",
      " Bernie Sanders \n",
      "\n",
      "I'm not sure that Straightinfo fully appreciates what NPOV means, as exampled here:What this comes down to is Bkwillwm feels any comment which might make Sanders \"\"look bad\"\", is POV, even though the intent of the information is to present neutrality by giveng both sides at once.  It isn't about reproducing two opposite pointed views, but instead giving all the pertinant information and letting the reader draw their own conclusions. The user removed the POV flag without any consensus with other users and then dropped a few weasel wordings into the Bernie Sanders article. Advice and guidence would be very appreciated.  \"\n",
      "* * * * * * * * * \n",
      "127090\n",
      "What if CISPA bill became DNSchanger virus, Google, FB and others cannot promisr our privacy but instead infect all our computers filled with devastating virusrs that government cannot handle them. Insead they spy our information (like virusrs), we get infected. As soon as it gets too contagious. What about NoKoR Nuclear missile to interfere CISPA with Kim Jong Un?\n",
      "* * * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm.predict(X_train)\n",
    "\n",
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(svm_predictions)):\n",
    "    if (svm_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [svm_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3244, 'Neg': 28671, 'TP': 2357, 'TN': 28067, 'FP': 604, 'FN': 887, 'Accuracy': 0.9532821557261476, 'Precision': 0.796014859844647, 'Recall': 0.7265721331689272, 'desc': 'svm_test'}\n"
     ]
    }
   ],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0          72          10\n",
      "1          13           1\n",
      "2          16           0\n",
      "3          38           3\n",
      "4           7           1\n",
      "5          16           2\n",
      "6          31           4\n",
      "7           6           1\n",
      "8         109           9\n",
      "9          41           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 131074)\n",
      "(153164, 131074)\n",
      "Shape of X_test for submission:\n",
      "(153164, 131074)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n"
     ]
    }
   ],
   "source": [
    "# read in test data for submission\n",
    "raw_data, X_test_submission = process_raw_data(fn='toxiccomments_test.csv', my_random_seed=42, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22704421404507585\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = svm.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC plot for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [svm_performance_test]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
