{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "    X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "    print(\"Shape of HashingVectorizer X:\")\n",
    "    print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    transformer = TfidfTransformer()\n",
    "    X_tfidf = transformer.fit_transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    X = sc.fit_transform(X_matrix)\n",
    "    print(X.shape)\n",
    "    if (not test):\n",
    "        y = toxic_data['any_toxic']\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0          42           5\n",
      "1          18           2\n",
      "2          42           3\n",
      "3         112           3\n",
      "4          13           1\n",
      "5          12           1\n",
      "6           8           0\n",
      "7          21           2\n",
      "8          83           7\n",
      "9          12           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 131074)\n",
      "(159571, 131074)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 131074)\n",
      "(31915, 131074)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 11)\n",
      "(31915, 11)\n",
      "SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='toxiccomments_train.csv', my_random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12981, 'Neg': 114675, 'TP': 11193, 'TN': 113838, 'FP': 837, 'FN': 1788, 'Accuracy': 0.9794369242338785, 'Precision': 0.9304239401496259, 'Recall': 0.8622602264848624, 'desc': 'svm_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier(loss='hinge', penalty='elasticnet', alpha=0.001, l1_ratio=0.5, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of false positives:\n",
      "1404\n",
      "Your time will come.\n",
      "* * * * * * * * * \n",
      "4351\n",
      "Please have a look at Wikipedia:Dick, thank you.\n",
      "* * * * * * * * * \n",
      "6035\n",
      "Hitler, The Game\n",
      "You lost it.\n",
      "* * * * * * * * * \n",
      "6335\n",
      "I dont care. I have at least one proof link. You are so stupid that you dont know how to translate my link. And of couse you dont have any argument or link. Additionaly you must read discussion page. And again. T-72 dont have any ammo in turret.\n",
      "* * * * * * * * * \n",
      "8133\n",
      "\"\n",
      " History and ethnogenesis \n",
      "\n",
      "This part of the article is total crap! It is written by some incompetent greeks probably. Neither the bulgarians are slavs, neither \"\"byzantine\"\"!!!\"\n",
      "* * * * * * * * * \n",
      "8512\n",
      "Carlo Forlivesi \n",
      "\n",
      "You mention Google News? A search on the guy returns a measly 8 results from the archives.\n",
      "\n",
      "Say what you will, the page is OBVIOUS and shameless self-promotion by a complete nobody.\n",
      "\n",
      "Not that I expect Wikipedia to ever become anything serious or reliable (it's mostly a pile of bullshit anyway) but at least this kind of crap used to be removed. If that's no longer the case, well, that just gives even more weight to the point I make on my user page.\n",
      "* * * * * * * * * \n",
      "9099\n",
      "Though he is a tyrant, the way Bush Administration executed him using the Iraq's puppet Government is worse the Saddam's tyranny.\n",
      "* * * * * * * * * \n",
      "9600\n",
      "\"\n",
      "\n",
      " Please do not vandalize pages, as you did with this edit to Bucephalus. If you continue to do so, you will be blocked from editing.   /talk to me/ \"\n",
      "* * * * * * * * * \n",
      "12041\n",
      "\"\n",
      "OK, I still have to fix the intro, but I am having difficulty finding any additional information about the bat's reproduction. Most sources simply say it is \"\"not well known\"\" or just mention what I've already said about a single annual offspring, so I'm not sure how to expand it any further. As for the false pelvic nipple, I have redescribed it as a pair of \"\"vestigial pubic nipple[s]\"\" as this seems to be a more common phrasing. talk \"\n",
      "* * * * * * * * * \n",
      "22604\n",
      "This latter site is obviously a front for Pakistani terrorists.\n",
      "* * * * * * * * * \n",
      "22711\n",
      "Good job for having your bully NeilN defend you.  You sure are a piece of work.  Goodbye Wikipedia, congratulations, you will never be accurate while you behave like this.  All I did was add accurate information.  Helen, hang your head in shame, in serious, severe shame.  I hope that you see the level of harm you have done, even if NeilN doesn't because his head is too far up his own backside to actually check any facts. 123.2.223.96\n",
      "* * * * * * * * * \n",
      "22813\n",
      "OH GET A LIFE YOU PRICK 81.144.199.2\n",
      "* * * * * * * * * \n",
      "28860\n",
      "Warning\n",
      "\n",
      "This message is regarding the page Penis. Please refrain from adding nonsense to Wikipedia.  It is considered vandalism.  If you would like to experiment, use the sandbox. —\n",
      "* * * * * * * * * \n",
      "31089\n",
      "\"{{{{ You will not remove the tag because I will put it back up. And I will not reove any \"\"national insult\"\". The world would be a lot better of a place if every Brit got infected and died from AIDS. But that is besdies the point.\n",
      "\n",
      "The section on \"\"Criticism of Amrerica' is unwarranted, one-sided, and a half attempt to divert responsibility away from British Petroleum. Also, the Lockerbie bomber hs everything to do with this oil spill since we are seeing everything come to light in the U.S. Senate inquiry not to mention accusations by President Obama and Hillary Rodham Clinton. By that same assumption, I ask, what the fuck does Union Carbide have to do with the B.P. ooil spill Obviously an editor had no qualms about including that in it's \"\"criticism of America.\"\"  \n",
      "\n",
      "\"\n",
      "* * * * * * * * * \n",
      "36603\n",
      "Its so simple. If you have a proxy located in Japan, you can easily fool people that you are editing from Japan!\n",
      "* * * * * * * * * \n",
      "39258\n",
      "God says is enough!\n",
      "I know you and Russian fascists read this. Your hatred is well known to God! Jesus stops you!\n",
      "* * * * * * * * * \n",
      "41054\n",
      "Yes, I think my zoology lecturer described a coral as a medusa that unaccountably stood on its head and built itself a house... I've added refs for most of the more egregious bits of OR and have tidied up the books. The human section doesn't seem to me to need much doing to it; I think we ought to do something about the fossils, for taxobox, phylogeny and diversity (e.g., we should illustrate tabulate, rugose etc alongside (in a table?) some sort of description of the groups  name, time range from-to, description, ref, image (or something). BTW I shall be offline all next week.\n",
      "* * * * * * * * * \n",
      "50843\n",
      "HE DELETED ARTICLES I DID CREATE WITHOUT TALKING. THIS IS BAD AND MEAN. I WANT THAT HE GETS DE-ADMINED.\n",
      "\n",
      "DELETING ARTICLES IS NO LITTLE THING FOR NON-ADMIN USERS.\n",
      "\n",
      "IT IS UGLY, MEAN, ARROGANT TO DO SO.\n",
      "* * * * * * * * * \n",
      "53202\n",
      "\"\n",
      " Welcome to Wikipedia, where you're either with us or against us. Apparently it's been decided you're in the \"\"against\"\" column. So much for \"\"[making] the Internet not suck\"\" eh? \"\n",
      "* * * * * * * * * \n",
      "58034\n",
      "It is not racist \n",
      "\n",
      "what i post, you are just a PC race denier\n",
      "* * * * * * * * * \n",
      "58103\n",
      "Yep, because Jeremy should ONLY be painted in a positive light.  Why?  Because how else will he fool everybody into believing he's harmless?  I DO know Jeremy personally, this is one of the reasons I have a personal problem with him.  And I'll be damned if I'm going to let some bleeding heart whitewash this guy and turn him into some kind of wannabe saint/hero.  He's not a saint.  He's not a hero.  He's a stupid script kiddie who got himself caught, tried to weasel out, and went to jail for his crime as he should have.\n",
      "* * * * * * * * * \n",
      "65582\n",
      "not covered in the article \n",
      "\n",
      "John Hughes was a notable cum guzzler - this is somewhat noteworthy right? The habit helped him in terms of idea generation and development for 16 Candles (referenced in Youtube Edition Mindfuck Doggystyle with Penry Rames.)\n",
      "* * * * * * * * * \n",
      "65793\n",
      "Sockpuppet investigation\n",
      "* * * * * * * * * \n",
      "66653\n",
      "hurt you and you will be sorry\n",
      "* * * * * * * * * \n",
      "67194\n",
      "What you just typed a while ago does imply that you believe that Barricade is in the movie.\n",
      "* * * * * * * * * \n",
      "70528\n",
      "Calling someones actions stupid is not the same as calling the person stupid and telling the to grow up is poititive critisism not a personal attack...\n",
      "\n",
      "what planet do you live on....94.168.210.205\n",
      "* * * * * * * * * \n",
      "70914\n",
      "\"== \"\"Somebody's Watching Me\"\" ==\n",
      "The recording used in the GEICO commercials is not a remix. It's clearly a new (or different) recording; the singer featured is definitely NOT Michael Jackson.   \"\n",
      "* * * * * * * * * \n",
      "73994\n",
      "Unforunately, for 90% of the students who attend SGU (including myself), we didn't get into US based schools. My earlier edits to add more information was putting a line in which is FACT. It is you who must prove that line to be false because I am a student at that university. I am putting that line back in.\n",
      "* * * * * * * * * \n",
      "79370\n",
      "\"\n",
      "\n",
      "Sentence in \"\"Ergot Theory\"\"\n",
      "\n",
      "I'm not really satisfied with this sentence \"\"A new study has shown that a primitive form of LSD was infecting the wheat supply on one side of the village. \"\"  First off, what study? There is no reference cited so this could be some wackos study or it could be something reputable. Also, the sources I've cited in the rest of this section were all discussing RYE not wheat. This is the lone sentence about wheat and I have no idea whether ergot (which I assume is what is meant by \"\"a primitive form of LSD\"\") on wheat does the same as ergot on rye.  I propose the sentence be edited out unless it can be expanded by citing some verifiable study.  \"\n",
      "* * * * * * * * * \n",
      "82857\n",
      "Pontiac Monrana \n",
      "\n",
      "Karrmann you full of shit ibelive all of the people who know that the montan will return after 2008\n",
      "\n",
      "and we want ot knwo ehre do you get your info form and can you sohw it \n",
      "\n",
      "and guess what you dont know anythng about the Montana\n",
      "* * * * * * * * * \n",
      "86056\n",
      "I Went and looked at the links on the page, Excellent job Guys and Gals, You are greatly helping me, why the number of links has nearly tripled! My project may yet be saved!\n",
      "* * * * * * * * * \n",
      "90747\n",
      "You have no respect for the victims, you are with the killers.\n",
      "* * * * * * * * * \n",
      "92736\n",
      "This is futile as  I mentioned. There are multiple sources confirming Ali's apostasy from Islam. Can you demonstrate that Warraq is not trustworthy?  (talk•contribs)\n",
      "* * * * * * * * * \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98199\n",
      "Thank you for all the fun crap and allowing them to do what ever they want to\n",
      "\n",
      "Hope your happy they win there right im not\n",
      "* * * * * * * * * \n",
      "99786\n",
      "Having fun?\n",
      "Another of your racist admins just deleted my response again and u keep lying about me.\n",
      "* * * * * * * * * \n",
      "110252\n",
      "Makes me want to vomit\n",
      "The way they're hand holding SPUI especially after the way they treated me, yourself and Gateman. Especially how I was permbanned even though truth and evidence were on my side. I'm starting to wonder if this project is anything but a who knows who club. I could get 50,000 edits pretty quick too making the type of crap redirect edits he does.\n",
      "* * * * * * * * * \n",
      "111243\n",
      "pretending to be anti-fascist\n",
      "* * * * * * * * * \n",
      "111908\n",
      "Truth is an absolute defense to libel.  You are lying.  And you are harassing me.\n",
      "* * * * * * * * * \n",
      "116275\n",
      "\"\n",
      "\n",
      "Chapter List, disputed information\n",
      "While defunct chapters have been noted with an asterik, some listed chapters, notably the \"\"colonies\"\" are not officially recognized.  IMHO it is irresponsible to list those which either AEPi national, or local instituions do not officially recognize. \n",
      "\n",
      "Proposed solutions:\n",
      " remove the colony section. \n",
      " harsh, possibly unproductive\n",
      " remove all unrecongized groups from the colony section. \n",
      " create subsections noting nationally & institutionally recognized, either or and none of the above.\n",
      " confusing and would not conform with Wiki-standards\n",
      " identify those colonies which are officially recognized by National and those recognized by the institition (similar to the asterik phenomena)\"\n",
      "* * * * * * * * * \n",
      "120799\n",
      "What's your problem? \n",
      "\n",
      "Stop being so racist. 78.145.156.74\n",
      "* * * * * * * * * \n",
      "122798\n",
      "\"\n",
      "\n",
      "I'm not sure that your statement on this \"\"fawning article\"\" by someone you characterize as a \"\"conspiracy nut\"\" is in compliance with WP:NPOV.   \"\n",
      "* * * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm.predict(X_train)\n",
    "\n",
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(svm_predictions)):\n",
    "    if (svm_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAd8UlEQVR4nO3de7wVdf3v8debm6ggplBHuYknzFADYWvqr37iw0toCuZR0ZOZZfKzsjpZeUlTj50u6u9k+Qt/hlkQnRSyVFSMblp5Z2toiqlIqIQ/RUVTIBH8nD/miyy2aw2zt8xaa+/9fj4e89gzs74z81njdr+Z23cUEZiZmdXSo9EFmJlZc3NQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HhVkFSSdJur3RdZg1EweFNYykJZJWS3pV0n9Jmi6pX5s2+0n6vaRXJL0s6UZJo9q02UbSdyU9lda1KE0PLLn+2yR9qh3td5IUknpthm1Pl/R/3u56qqx3vKSlm3u91rk5KKzRjoiIfsAYYE/g7PUfSNoX+DVwA7AjMAJ4ALhD0s6pTR/gd8BuwARgG2A/4AVg7/p9DbMuLCI8eGjIACwBDqqYvhi4uWL6T8DlVZa7BfhJGv8U8CzQrx3bDeDzwGLgeeASoEf67CTg9oq2+wHzgZfTz/3S/G8A64B/Aq8C3y+w3afStl9Nw75p/ieBR4AVwDxgeJov4FLgubT9B4HdgSnA68CatJ4bq2yr6rLpsy2Af0/1PAtcAWwJbA2sBt6oqHHHRv+eeGj84CMKawqShgCHAovS9FZkf6R/XqX5bODgNH4Q8KuIeLWdm/wI0AKMBSaR/bFuW9N2wM3AZcD2wHeAmyVtHxHnkAXZaRHRLyJOS8vcJOmsGtv81/Rz27TMXZKOBL4KHAUMSuu8OrU7JC2zC7AtMBl4ISKmAf8PuDit54gq26q6bPrsojR/DPBuYDBwXkSsJPtvsCytt19ELKu9C627cFBYo10v6RXgabJ//Z6f5m9H9vv5TJVlngHWX3/YvkabTbkoIl6MiKeA7wLHV2nzYeDxiJgZEWsj4mrgr0C1P8wARMThEfHtdtTxb8C3IuKRiFgLfBMYI2k42VFDf2BXQKlN0e9adVlJAk4Bvpi+/ytpm8e1o2brZhwU1mhHRkR/YDzZH7X1AbCC7BTIDlWW2YHslBFk/0qu1mZTnq4Yf5LsGkhbO6bPaNN2cAe2V8tw4HuSXpL0EvAi2WmjwRHxe+D7wFTgWUnTJG1TZKU5yw4CtgLuq9jmr9J8s6ocFNYUIuIPwHSyc+ek0yB3AcdUaX4s2QVsgN8CH5K0dTs3ObRifBhQ7RTLMrI/5LRp+/f1Zbdzm9XaPw38W0RsWzFsGRF3AkTEZRExjuxi/S7AV4puu8ayz5Ndh9itYnsDIruhoCPfyboBB4U1k+8CB0sak6bPAj4u6fOS+kt6R7oldF/gf6c2M8n+2P5C0q6SekjaXtJXJR2Ws62vpPUNBb4AzKrSZi6wi6T/KamXpMnAKOCm9PmzwM7t+H7LyY6SKpe5Ajhb0m4AkgZIOiaN7yXp/ZJ6AyvJLpyvK7LtWstGxBvAlcClkt6Z2g6W9KGK9W4vaUA7vpd1cQ4KaxoRsRz4CfC1NH078CGyC73PkJ322RP4QEQ8ntq8RnZB+6/Ab4B/APeSncK6J2dzNwD3AQvILlhfVaWeF4DDgS+RneI6Azg8Itaf9voecLSkFZIuA5B0i6Sv1vh+q8julrojnfbZJyKuI7u4fI2kfwAPkV1QhuxW3yvJTsM9mWr49/TZVcCotJ7rq2wub9kzyW4auDtt87fAe1KNfyW7mL44rbvaKTnrZhThI03rXiQFMDIiFjW6FrPOwEcUZmaWq7SgkPQjSc9JeqjG55J0Wepu4UFJY8uqxczMOq7MI4rpZF0q1HIoMDINU4D/LLEWszdFhHzayay40oIiIv5Idk94LZPIumGIiLgb2FZSR+6HNzOzEr3tXizfhsFs/NDT0jTvLU+eSppCdtTB1ltvPW7XXXetS4FmZl3Ffffd93xEdOjBykYGharMq3oLVurbZhpAS0tLtLa2llmXmVmXI6ltLwOFNfKup6Vs/HTsEKo/HWtmZg3UyKCYA5yY7n7aB3i5HR2emZlZnZR26knS1WQdvQ1Mb8w6H+gNEBFXkHWPcBjZE6KrgE+UVYuZmXVcaUEREdW6ba78PIDPlrV9MzPbPPxktpmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HhZmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HhZmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HxSYsWLCAuXPntnu5ZcuWcfTRR5dQkZlZfTkoNiEvKNauXVtzuR133JFrr722rLLMzOqmUwfFypUr+fCHP8zo0aPZfffdmTFjBscee+ybn992220cccQRAPTr148zzzyTcePGcdBBB3Hvvfcyfvx4dt55Z+bMmVN1/WvWrOG8885j1qxZjBkzhlmzZnHBBRcwZcoUDjnkEE488USWLFnCBz/4QcaOHcvYsWO58847AViyZAm77747ANOnT+eoo45iwoQJjBw5kjPOOKPkPWNmthlFRKcaxo0bFz/9acTw4RFwbfTr96n46U8jIiJeeumlGDp0aLz66qsREXHqqafGzJkzIyICiLlz50ZExJFHHhkHH3xwrFmzJhYsWBCjR4+OWn784x/HZz/72Tenzz///Bg7dmysWrUqIiJWrlwZq1evjoiIxx57LMaNGxcREX/7299it912e3MdI0aMiJdeeilWr14dw4YNi6eeeqrmNs3MNjegNTr4d7fTHVG8+CJMmQJPPgmwB6+++ltOOulMvva1PzFgwAAmTJjAjTfeyNq1a7n55puZNGkSAH369GHChAkA7LHHHuy///707t2bPfbYgyVLlrSrhokTJ7LlllsC8Prrr3PKKaewxx57cMwxx7Bw4cKqyxx44IEMGDCAvn37MmrUKJ7MvoCZWdPr1egC2uvvf4c1a9ZP7QLcx9q1c7nkkrPp3fsQJk+ezNSpU9luu+3Ya6+96N+/PwC9e/dGEgA9evRgiy22eHM871pDNVtvvfWb45deeinvete7eOCBB3jjjTfo27dv1WXWbw+gZ8+e7d6mmVmjdLojig0hAbAM2Ao4gdde+zL3338/48eP5/777+fKK69k8uTJb3t7/fv355VXXqn5+csvv8wOO+xAjx49mDlzJuvWrXvb2zQzayadLij69Kmc+guwNzCGPn2+wbnnnkvPnj05/PDDueWWWzj88MPf9vYOOOAAFi5c+ObF7LY+85nPMGPGDPbZZx8ee+yxjY42zMy6AmXXODqPnXduiWefbWXVqg3zttoKpk2Dj360cXWZmTUzSfdFREtHlu10RxTbbZeFwvDhIGU/HRJmZuXpdBezIQuFzR0M8+bN48wzz9xo3ogRI7juuus274bMzDqZTnfqqaWlJVpbWxtdhplZp9KtTj2ZmVl9OSjMzCyXg8LMzHI5KMzMLJeDwszMcpUaFJImSHpU0iJJZ1X5fJikWyX9WdKDkg4rsx4zM2u/0oJCUk9gKnAoMAo4XtKoNs3OBWZHxJ7AccDlZdVjZmYdU+YRxd7AoohYHBFrgGuASW3aBLBNGh9A1sufmZk1kTKDYjDwdMX00jSv0gXACZKWAnOBz1VbkaQpkloltS5fvryMWs3MrIYyg0JV5rV9DPx4YHpEDAEOA2ZKektNETEtIloiomXQoEEllGpmZrWUGRRLgaEV00N466mlk4HZABFxF9AXGFhiTWZm1k5lBsV8YKSkEZL6kF2sntOmzVPAgQCS3ksWFD63ZGbWREoLiohYC5wGzAMeIbu76WFJF0qamJp9CThF0gPA1cBJ0dl6KTQz6+JK7WY8IuaSXaSunHdexfhC4F/KrMHMzN4eP5ltZma5HBRmZpbLQWFmZrkcFGZmlstBYWZmuRwUZmaWy0FhZma5HBRmZpbLQWFmZrkcFGZmlstBYWZmuRwUZmaWy0FhZma5HBRmZpbLQWFmZrkcFGZmlstBYWZmuTYZFJK2lHS2pCvS9LslHVp+aWZm1gyKHFH8CBDwgTS9DPhmaRWZmVlTKRIUIyPim8DrABGxiiw4zMysGygSFGsk9QUCQNIIYE2pVZmZWdPoVaDN14FfAUMkzQD2Bz5ValVmZtY0NhkUEXGLpFZgP7JTTl+JiOdKr8zMzJpCkbuefh0RyyPihoi4PiKek/TrehRnZmaNV/OIQlIfoC/wLkn92XABextgWB1qMzOzJpB36umzwOnAO4GH2RAU/wCuKLkuMzNrEjWDIiIuBS6V9L8i4rt1rMnMzJpIkYvZ35W0KzCK7FTU+vk/K7MwMzNrDpsMCknnAocAuwLzgA8BtwMOCjOzbqDIA3eTgQOAZyLiY8Boij1/YWZmXUCRoFgdEeuAtenup/8Cdi63LDMzaxZFjgz+LGlbss4BW8nuerq/1KrMzKxp5AaFJAEXRMRLwFRJ84BtIsJBYWbWTeSeeoqIAG6qmF7kkDAz616KXKO4V9LYjqxc0gRJj0paJOmsGm2OlbRQ0sOSfCeVmVmTKXKN4gPAKZKeAFaSPaEdEZEbHpJ6AlOBg4GlwHxJcyJiYUWbkcDZwL9ExApJ7+zg9zAzs5IUCYojO7juvYFFEbEYQNI1wCRgYUWbU4CpEbECwL3Smpk1nyJPZj/RwXUPBp6umF4KvL9Nm10AJN0B9CS7cP6rtiuSNAWYAjBsmPsjNDOrpyLXKDqq2utSo810L2AkMB44HvhhuhV344UipkVES0S0DBo0aLMXamZmtZUZFEuBoRXTQ4BlVdrcEBGvR8TfgEfJgsPMzJpEoaCQNETSAWl8C0lbF1hsPjBS0oj0bovjgDlt2lxP1j0IkgaSnYpaXLR4MzMrX5E33H2S7A/8D9Os4cANm1ouItYCp5F1JPgIMDsiHpZ0oaSJqdk84AVJC4FbyV6z+kL7v4aZmZVF2TN1OQ2kBWR3MN0TEXumeQ9GxPvqUN9btLS0RGtrayM2bWbWaUm6LyJaOrJskVNP/4yINRUb60n1C9VmZtYFFQmKOySdAfRN1ylmUdGth5mZdW1FguIM4BXgr8AXgN8B55RZlJmZNY8iT2YfBvwwIv6z7GLMzKz5FDmiOBZYJOnHkj6UrlGYmVk3scmgSK8/3QW4EfgksFjSFWUXZmZmzaHQu68j4jVJNwCryfpkOhY4tczCzMysORR54O4gST8EngBOAH4C/LeyCzMzs+ZQ5IjiVOAa4HMRsbrkeszMrMkU6Wb86HoUYmZmzalmUEj6Q0TsL2kFG3cPvv4Nd9uVXp2ZmTVc3hHFAennwHoUYmZmzanmxeyIeCONXhUR6yoH4Kr6lGdmZo1W5IG7jXqJTQ/c7VVOOWZm1mxqBoWkM9P1ifdJejENK4DlwNy6VWhmZg2Vd0RxMTAIuDT9HAQMjIjtIuIr9SjOzMwaL+9i9rsj4nFJM4Hd1s+UsldRRMSDJddmZmZNIC8ozgJOBqZW+SyAfy2lIjMzayo1gyIiTk4/P1i/cszMrNkU6evpKEn90/hZkmZLGl1+aWZm1gyK3B57QUS8Imk/4AiyV6H+oNyyzMysWRQJinXp5+HA5RHxC2CL8koyM7NmUqT32GckTQUOBcZJ6kOxgDEzsy6g6KtQ/wAcFhEryPp+OqvUqszMrGkUeRXqq8BCYLykU4F3RMQtpVdmZmZNochdT6cBs4FhaZgt6TNlF2ZmZs2hyDWKKcDe6cgCSd8E7gQuL7MwMzNrDkWuUQh4vWL69TTPzMy6gSJHFDOBuyX9giwgjgRmlFqVmZk1jSLvzL5Y0q3A+q48To2I+eWWZWZmzaLIEQXAa2l4I/00M7NuoshdT+cAVwM7AEOAn0k6u+zCzMysORQ5ojgBGBcRqwAkfQO4D/hWmYWZmVlzKHLX05NsHCi9gMXllGNmZs2myBHFKuBhSfPIXlh0CHC7pO8ARMTpJdZnZmYNViQobk7DencXXbmkCcD3gJ7ADyPi2zXaHQ38HNgrIlqLrt/MzMpX5PbYqzqyYkk9yV6jejCwFJgvaU5ELGzTrj/weeCejmzHzMzKVWZ34XsDiyJicUSsAa4BJlVp93XgYuCfJdZiZmYdVGZQDAaerphemua9SdKewNCIuClvRZKmSGqV1Lp8+fLNX6mZmdVUOCgktfetdtX6g4qK9fUALgW+tKkVRcS0iGiJiJZBgwa1swwzM3s7ijxwt7ekvwCPp+nRkv6jwLqXAkMrpocAyyqm+wO7A7dJWgLsA8yR1FKwdjMzq4MiRxSXkb0v+wWAiHgAOKDAcvOBkZJGpNenHgfMWf9hRLwcEQMjYqeI2InsbqqJvuvJzKy5FAmKHhHxZJt56za1UESsBU4D5gGPALMj4mFJF0qa2P5SzcysEYo8R/G0pL2BSLe8fg54rMjKI2IuMLfNvPNqtB1fZJ1mZlZfRY4oPg2cTvYa1GfJriV8usyizMyseRR54O45susLZmbWDW0yKCRdScVtretFxJRSKjIzs6ZS5BrFbyvG+wIfYeMH6czMrAsrcuppVuW0pJnAb0qryMzMmkpHuvAYAQzf3IWYmVlzKnKNYgUbrlH0AF4EziqzKDMzax65QSFJwGjg72nWGxHxlgvbZmbWdeWeekqhcF1ErEuDQ8LMrJspco3iXkljS6/EzMyaUs1TT5J6pf6aPgCcIukJYCVZ9+EREQ4PM7NuIO8axb3AWODIOtViZmZNKC8oBBART9SpFjMza0J5QTFI0um1PoyI75RQj5mZNZm8oOgJ9KP6K03NzKybyAuKZyLiwrpVYmZmTSnv9lgfSZiZWW5QHFi3KszMrGnVDIqIeLGehZiZWXPqSO+xZmbWjTgozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxylRoUkiZIelTSIklnVfn8dEkLJT0o6XeShpdZj5mZtV9pQSGpJzAVOBQYBRwvaVSbZn8GWiLifcC1wMVl1WNmZh1T5hHF3sCiiFgcEWuAa4BJlQ0i4taIWJUm7waGlFiPmZl1QJlBMRh4umJ6aZpXy8nALdU+kDRFUquk1uXLl2/GEs3MbFPKDApVmRdVG0onAC3AJdU+j4hpEdESES2DBg3ajCWamdmm9Cpx3UuBoRXTQ4BlbRtJOgg4B9g/Il4rsR4zM+uAMo8o5gMjJY2Q1Ac4DphT2UDSnsAPgIkR8VyJtZiZWQeVFhQRsRY4DZgHPALMjoiHJV0oaWJqdgnQD/i5pAWS5tRYnZmZNUiZp56IiLnA3DbzzqsYP6jM7ZuZ2dvnJ7PNzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsV6lBIWmCpEclLZJ0VpXPt5A0K31+j6SdyqzHzMzar7SgkNQTmAocCowCjpc0qk2zk4EVEfFu4FLgorLqMTOzjinziGJvYFFELI6INcA1wKQ2bSYBM9L4tcCBklRiTWZm1k69Slz3YODpiumlwPtrtYmItZJeBrYHnq9sJGkKMCVNvibpoVIq7nwG0mZfdWPeFxt4X2zgfbHBezq6YJlBUe3IIDrQhoiYBkwDkNQaES1vv7zOz/tiA++LDbwvNvC+2EBSa0eXLfPU01JgaMX0EGBZrTaSegEDgBdLrMnMzNqpzKCYD4yUNEJSH+A4YE6bNnOAj6fxo4HfR8RbjijMzKxxSjv1lK45nAbMA3oCP4qIhyVdCLRGxBzgKmCmpEVkRxLHFVj1tLJq7oS8LzbwvtjA+2ID74sNOrwv5H/Am5lZHj+ZbWZmuRwUZmaWq2mDwt1/bFBgX5wuaaGkByX9TtLwRtRZD5vaFxXtjpYUkrrsrZFF9oWkY9PvxsOSflbvGuulwP8jwyTdKunP6f+TwxpRZ9kk/UjSc7WeNVPmsrSfHpQ0ttCKI6LpBrKL308AOwN9gAeAUW3afAa4Io0fB8xqdN0N3BcHAFul8U93532R2vUH/gjcDbQ0uu4G/l6MBP4MvCNNv7PRdTdwX0wDPp3GRwFLGl13SfviX4GxwEM1Pj8MuIXsGbZ9gHuKrLdZjyjc/ccGm9wXEXFrRKxKk3eTPbPSFRX5vQD4OnAx8M96FldnRfbFKcDUiFgBEBHP1bnGeimyLwLYJo0P4K3PdHUJEfFH8p9FmwT8JDJ3A9tK2mFT623WoKjW/cfgWm0iYi2wvvuPrqbIvqh0Mtm/GLqiTe4LSXsCQyPipnoW1gBFfi92AXaRdIekuyVNqFt19VVkX1wAnCBpKTAX+Fx9Sms67f17ApTbhcfbsdm6/+gCCn9PSScALcD+pVbUOLn7QlIPsl6IT6pXQQ1U5PeiF9npp/FkR5l/krR7RLxUcm31VmRfHA9Mj4j/K2lfsue3do+IN8ovr6l06O9msx5RuPuPDYrsCyQdBJwDTIyI1+pUW71tal/0B3YHbpO0hOwc7JwuekG76P8jN0TE6xHxN+BRsuDoaorsi5OB2QARcRfQl6zDwO6m0N+Ttpo1KNz9xwab3BfpdMsPyEKiq56Hhk3si4h4OSIGRsROEbET2fWaiRHR4c7QmliR/0euJ7vRAUkDyU5FLa5rlfVRZF88BRwIIOm9ZEGxvK5VNoc5wInp7qd9gJcj4plNLdSUp56ivO4/Op2C++ISoB/w83Q9/6mImNiwoktScF90CwX3xTzgEEkLgXXAVyLihcZVXY6C++JLwJWSvkh2quWkrvgPS0lXk51qHJiux5wP9AaIiCvIrs8cBiwCVgGfKLTeLrivzMxsM2rWU09mZtYkHBRmZpbLQWFmZrkcFGZmlstBYWZmuRwU1rQkrZO0oGLYKaftTrV6zKw3SS2SLkvj4yXtV/HZqZJOrGMtY7pqT6lWP035HIVZsjoixjS6iPZKD/itf8hvPPAqcGf67IrNvT1JvVJ/Z9WMIevWZe7m3q51Hz6isE4lHTn8SdL9adivSpvdJN2bjkIelDQyzT+hYv4PJPWssuwSSReldvdKeneaP1zZuz7Wv/NjWJp/jKSHJD0g6Y9p3nhJN6UjoFOBL6ZtflDSBZK+LOm9ku5t870eTOPjJP1B0n2S5lXr3VPSdEnfkXQrcJGkvSXdqex9C3dKek96SvlCYHLa/mRJWyt7Z8H81LZa77tmG2t0/+kePNQayJ4mXpCG69K8rYC+aXwk2ZO3ADuR+uAH/gP4aBrvA2wJvBe4Eeid5l8OnFhlm0uAc9L4icBNafxG4ONp/JPA9Wn8L8DgNL5t+jm+YrkLgC9XrP/N6fS9dk7jZwLnkj1FeycwKM2fTPakcds6pwM3AT3T9DZArzR+EPCLNH4S8P2K5b4JnLC+XuAxYOtG/7f20NyDTz1ZM6t26qk38H1JY8iCZJcqy90FnCNpCPDLiHhc0oHAOGB+6uZkS6BWv1hXV/y8NI3vCxyVxmeSve8C4A5guqTZwC/b8+XIOqk7Fvg2WSBMBt5D1rHhb1KdPYFaffH8PCLWpfEBwIx09BSkbhuqOASYKOnLabovMAx4pJ21WzfioLDO5ovAs8BoslOnb3k5UUT8TNI9wIeBeZI+Rda98oyIOLvANqLG+FvaRMSpkt6ftrUgBVhRs8j65/pltqp4XNIewMMRsW+B5VdWjH8duDUiPpJOed1WYxkB/yMiHm1HndbN+RqFdTYDgGcie4/Ax8j+xb0RSTsDiyPiMrLeMt8H/A44WtI7U5vtVPvd4pMrft6Vxu9kQ8eTHwVuT+v57xFxT0ScBzzPxl04A7xC1v35W0TEE2RHRV8jCw3IugIfpOydCUjqLWm3GnVWGgD8PY2flLP9ecDnlA5XlPU8bJbLQWGdzeXAxyXdTXbaaWWVNpOBhyQtAHYle/XjQrJrAL9OF41/A9R6BeQW6YjkC2RHMACfBz6Rlv1Y+gzgEkl/Sbfm/pHsfc2VbgQ+sv5idpVtzQJOYMO7EtaQdZt/kaQHyK5jvOWCfRUXA9+SdAcbh+etwKj1F7PJjjx6Aw+mmr9eYN3Wzbn3WLMKyl541BIRzze6FrNm4SMKMzPL5SMKMzPL5SMKMzPL5aAwM7NcDgozM8vloDAzs1wOCjMzy/X/AWCyHTHcjlumAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [svm_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3244, 'Neg': 28671, 'TP': 2309, 'TN': 28045, 'FP': 626, 'FN': 935, 'Accuracy': 0.951088829703901, 'Precision': 0.7867120954003407, 'Recall': 0.7117755856966708, 'desc': 'svm_test'}\n"
     ]
    }
   ],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 131072)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0          72          10\n",
      "1          13           1\n",
      "2          16           0\n",
      "3          38           3\n",
      "4           7           1\n",
      "5          16           2\n",
      "6          31           4\n",
      "7           6           1\n",
      "8         109           9\n",
      "9          41           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 131074)\n",
      "(153164, 131074)\n",
      "Shape of X_test for submission:\n",
      "(153164, 131074)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n"
     ]
    }
   ],
   "source": [
    "# read in test data for submission\n",
    "raw_data, X_test_submission = process_raw_data(fn='toxiccomments_test.csv', my_random_seed=42, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17757436473322713\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = svm.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC plot for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [svm_performance_test]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
